{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install cantera\n",
        "!pip install torchdiffeq\n",
        "!pip install pandas"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zvXi1WPlqncw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6x9Q2gMqlKL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchdiffeq import odeint\n",
        "import cantera as ct\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\\n\")\n",
        "\n",
        "# Define temperature groups\n",
        "TEMPERATURE_GROUPS = {\n",
        "    'high': [1900, 2100, 2300],\n",
        "    'medium': [1500, 1700, 1900],\n",
        "    'low': [900, 1100, 1300, 1500]\n",
        "}\n",
        "\n",
        "# =============================================\n",
        "# 1. Training Data Generation with Cantera\n",
        "# =============================================\n",
        "\n",
        "def generate_training_data():\n",
        "    # Define ammonia-air mechanism\n",
        "    gas = ct.Solution('/content/sample_data/okafor.yaml')\n",
        "\n",
        "    # Define initial conditions\n",
        "    equivalence_ratios = np.arange(0.6, 1.5, 0.2)  # phi = 0.6 to 1.4\n",
        "    temperatures = list(set(t for group in TEMPERATURE_GROUPS.values() for t in group))\n",
        "    temperatures.sort()\n",
        "    N_samples = 10000  # Number of points per condition\n",
        "\n",
        "    # Species to track (major species)\n",
        "    species = ['NH3', 'O2', 'H2', 'OH', 'H2O', 'N2', 'NO']\n",
        "\n",
        "    # Storage for all data\n",
        "    all_data = []\n",
        "\n",
        "    for T_init in temperatures:\n",
        "        for phi in equivalence_ratios:\n",
        "            # Set initial state\n",
        "            gas.set_equivalence_ratio(phi, 'NH3', 'O2:1.0, N2:3.76')\n",
        "            gas.TP = T_init, ct.one_atm\n",
        "\n",
        "            # Create reactor\n",
        "            reactor = ct.IdealGasConstPressureReactor(gas)\n",
        "            sim = ct.ReactorNet([reactor])\n",
        "            rtol, atol = 1e-12, 1e-16\n",
        "            sim.rtol, sim.atol = rtol, atol\n",
        "            print(f\"\\nGenerating Training Data for (T, φ) = ({T_init}, {phi.round(1)})\")\n",
        "\n",
        "            # Compute ignition delay time (tau_ign)\n",
        "            if T_init == 900:\n",
        "                # tau_ign = calculate_ignition_delay_time_dynamic(phi, T, P, mechanism)\n",
        "                tau_ign_info = \"~10³ seconds\"\n",
        "                t_elap = 5\n",
        "                dt = t_elap / N_samples\n",
        "            elif T_init == 1100:\n",
        "                tau_ign = 14.50   # calculate_ignition_delay_time_dynamic(phi, T, P, mechanism)\n",
        "                t_elap = 5\n",
        "                dt = t_elap / N_samples\n",
        "            else:\n",
        "                tau_ign = calculate_ignition_delay_time_dynamic(phi, T_init, ct.one_atm, '/content/sample_data/okafor.yaml')\n",
        "                dt = 4 * tau_ign / N_samples\n",
        "                t_elap = 4 * tau_ign\n",
        "\n",
        "            # Storage for this condition\n",
        "            wdot = reactor.thermo.net_production_rates * reactor.thermo.molecular_weights / reactor.thermo.density\n",
        "            condition_data = {\n",
        "                'phi': phi,\n",
        "                'T_init': T_init,\n",
        "                'times': [0.0],\n",
        "                'T': [reactor.T],\n",
        "                'Y': [np.array([reactor.thermo[sp].Y[0] for sp in species])],\n",
        "                'dYdt': [np.array([wdot[reactor.thermo.species_index(sp)] for sp in species])]\n",
        "            }\n",
        "\n",
        "            # Run simulation\n",
        "            while sim.time < t_elap:\n",
        "                sim.step()\n",
        "                if len(condition_data['times']) == 0 or sim.time - condition_data['times'][-1] >= dt:\n",
        "                    condition_data['times'].append(sim.time)\n",
        "                    condition_data['T'].append(reactor.T)\n",
        "\n",
        "                    # Get mass fractions and reaction rates\n",
        "                    Y = np.array([reactor.thermo[sp].Y[0] for sp in species])\n",
        "                    condition_data['Y'].append(Y)\n",
        "\n",
        "                    # Get reaction rates (dY/dt)\n",
        "                    wdot = reactor.thermo.net_production_rates * reactor.thermo.molecular_weights / reactor.thermo.density\n",
        "                    dYdt = np.array([wdot[reactor.thermo.species_index(sp)] for sp in species])\n",
        "                    condition_data['dYdt'].append(dYdt)\n",
        "\n",
        "            # Convert to numpy arrays\n",
        "            condition_data['Y'] = np.array(condition_data['Y'])\n",
        "            condition_data['dYdt'] = np.array(condition_data['dYdt'])\n",
        "            condition_data['T'] = np.array(condition_data['T'])\n",
        "\n",
        "            all_data.append(condition_data)\n",
        "\n",
        "    return all_data, species\n",
        "\n",
        "\n",
        "def calculate_ignition_delay_time_dynamic(equivalence_ratio, temperature, pressure, mechanism):\n",
        "    \"\"\"\n",
        "    Calculate the ignition delay time by fitting a sigmoid function\n",
        "    to the temperature profile and identifying the inflection point.\n",
        "\n",
        "    Parameters:\n",
        "        equivalence_ratio (float): Equivalence ratio of the mixture.\n",
        "        temperature (float): Initial temperature in K.\n",
        "        pressure (float): Initial pressure in Pa.\n",
        "        mechanism (str): Path to the chemical mechanism file.\n",
        "\n",
        "    Returns:\n",
        "        float: Ignition delay time in seconds.\n",
        "    \"\"\"\n",
        "    from scipy.optimize import curve_fit\n",
        "\n",
        "    # Sigmoid function for fitting\n",
        "    def sigmoid(t, L, k, t0, C):\n",
        "        return L / (1 + np.exp(-k * (t - t0))) + C\n",
        "\n",
        "    # Initialize gas and reactor\n",
        "    gas = ct.Solution(mechanism)\n",
        "    gas.TP = temperature, pressure\n",
        "    gas.set_equivalence_ratio(equivalence_ratio, fuel=\"NH3\", oxidizer=\"O2:1, N2:3.76\")\n",
        "\n",
        "    reactor = ct.IdealGasConstPressureReactor(gas)\n",
        "    sim = ct.ReactorNet([reactor])\n",
        "\n",
        "    # Time and data collection\n",
        "    t = 0.0\n",
        "    dt = 1e-6\n",
        "    if temperature == 900:\n",
        "        max_time = 25000.0\n",
        "    elif temperature == 1100:\n",
        "        max_time = 20.0\n",
        "    else:\n",
        "        max_time = 1.0\n",
        "\n",
        "    times = []\n",
        "    temperatures = []\n",
        "\n",
        "    # Simulation loop\n",
        "    if temperature in [900, 1100]:\n",
        "        while t < max_time:\n",
        "            sim.advance(t + dt)\n",
        "            t += dt\n",
        "            times.append(t)\n",
        "            temperatures.append(reactor.T)\n",
        "\n",
        "        # Convert lists to arrays\n",
        "        times = np.array(times)\n",
        "        temperatures = np.array(temperatures)\n",
        "\n",
        "        # Initial guess for sigmoid parameters\n",
        "        L_guess = max(temperatures) - min(temperatures)\n",
        "        k_guess = 1  # Guess steepness\n",
        "        t0_guess = times[np.argmax(np.gradient(temperatures, times))]  # Approximate midpoint\n",
        "        C_guess = min(temperatures)\n",
        "\n",
        "        # Fit the sigmoid function to the data\n",
        "        try:\n",
        "            popt, _ = curve_fit(sigmoid, times, temperatures, p0=[L_guess, k_guess, t0_guess, C_guess])\n",
        "            L, k, t0, C = popt  # Extract parameters\n",
        "            tau_ign = t0  # The inflection point corresponds to t0\n",
        "        except RuntimeError:\n",
        "            print(f\"Sigmoid fitting failed for T={temperature}, φ={equivalence_ratio.round(1)}.\")\n",
        "            tau_ign = np.nan\n",
        "\n",
        "        # Plot the results\n",
        "        # plt.figure(figsize=(8, 5))\n",
        "        # plt.plot(times, temperatures, label=\"Temperature Profile\")\n",
        "        # if not np.isnan(tau_ign):\n",
        "        #     sigmoid_fit = sigmoid(times, *popt)\n",
        "        #     plt.plot(times, sigmoid_fit, label=\"Sigmoid Fit\", linestyle=\"--\")\n",
        "        #     plt.axvline(tau_ign, color=\"red\", linestyle=\"--\", label=f\"Ignition Delay Time = {tau_ign:.4f} s\")\n",
        "        # plt.title(f\"Temperature Profile (T={temperature} K, φ={equivalence_ratio.round(1)})\")\n",
        "        # plt.xlabel(\"Time (s)\")\n",
        "        # plt.ylabel(\"Temperature (K)\")\n",
        "        # plt.legend()\n",
        "        # plt.grid(True)\n",
        "        # plt.show()\n",
        "\n",
        "        return tau_ign\n",
        "\n",
        "    else:\n",
        "        # Variables to track derivatives and store data\n",
        "        prev_temp = reactor.T\n",
        "        prev_dT_dt = 0.0\n",
        "        inflection_detected = False\n",
        "\n",
        "        while t < max_time:\n",
        "            sim.advance(t + dt)\n",
        "            t += dt\n",
        "            current_temp = reactor.T\n",
        "\n",
        "            # Record data for plotting\n",
        "            times.append(t)\n",
        "            temperatures.append(current_temp)\n",
        "\n",
        "            # Calculate first and second derivatives\n",
        "            dT_dt = (current_temp - prev_temp) / dt\n",
        "            d2T_dt2 = (dT_dt - prev_dT_dt) / dt\n",
        "\n",
        "            # Detect the inflection point\n",
        "            if not inflection_detected and prev_dT_dt > 0 and d2T_dt2 < 0:\n",
        "                inflection_detected = True\n",
        "                tau_ign = t\n",
        "                break\n",
        "\n",
        "            # Update previous values\n",
        "            prev_temp = current_temp\n",
        "            prev_dT_dt = dT_dt\n",
        "\n",
        "        # If no inflection point was detected, use the final time as fallback\n",
        "        if not inflection_detected:\n",
        "            print(f\"Warning: No inflection point found for T={temperature}, φ={equivalence_ratio.round(1)}. Using {t:.2f}s as fallback.\")\n",
        "            tau_ign = t\n",
        "\n",
        "        # Plot the temperature profile\n",
        "        # plt.figure(figsize=(8, 5))\n",
        "        # plt.plot(times, temperatures, label=\"Temperature Profile\")\n",
        "        # if inflection_detected:\n",
        "        #     plt.axvline(tau_ign, color=\"red\", linestyle=\"--\", label=f\"Ignition Delay Time = {tau_ign:.4f} s\")\n",
        "        # plt.title(f\"Temperature Profile (T={temperature} K, φ={equivalence_ratio.round(1)})\")\n",
        "        # plt.xlabel(\"Time (s)\")\n",
        "        # plt.ylabel(\"Temperature (K)\")\n",
        "        # plt.legend()\n",
        "        # plt.grid(True)\n",
        "        # plt.show()\n",
        "\n",
        "        return tau_ign\n",
        "\n",
        "# =============================================\n",
        "# 2. Execution\n",
        "# =============================================\n",
        "\n",
        "# Step 1: Generate training data\n",
        "print(\"Generating training data...\")\n",
        "all_data, species = generate_training_data()\n",
        "\n",
        "# Add species list to each condition data\n",
        "for data in all_data:\n",
        "    data['species'] = species\n",
        "print('\\nPrinting all_data[2]:\\n', all_data[2], '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# 3. Multi-scale Sampling with Density Weighting\n",
        "# =============================================\n",
        "\n",
        "def calculate_sampling_weights(data, target_species='NH3'):\n",
        "    \"\"\"Calculate sampling weights using kernel density estimation\"\"\"\n",
        "    # Extract target species mass fractions\n",
        "    Y_target = np.concatenate([d['Y'][:, d['species'].index(target_species)] for d in data])\n",
        "\n",
        "    # Kernel density estimation\n",
        "    kde = KernelDensity(bandwidth=0.01, kernel='gaussian')\n",
        "    kde.fit(Y_target.reshape(-1, 1))\n",
        "\n",
        "    # Calculate densities\n",
        "    log_dens = kde.score_samples(Y_target.reshape(-1, 1))\n",
        "    P = np.exp(log_dens)\n",
        "    P_min = np.min(P)\n",
        "\n",
        "    # Calculate weights\n",
        "    Q = P_min / P\n",
        "\n",
        "    # Assign weights back to each data point\n",
        "    start_idx = 0\n",
        "    weighted_data = []\n",
        "    for d in data:\n",
        "        n_points = len(d['Y'])\n",
        "        end_idx = start_idx + n_points\n",
        "        d['weights'] = Q[start_idx:end_idx]\n",
        "        weighted_data.append(d)\n",
        "        start_idx = end_idx\n",
        "\n",
        "    return weighted_data\n",
        "\n",
        "# =============================================\n",
        "# 4. Customized Box-Cox Transformation\n",
        "# =============================================\n",
        "\n",
        "class BoxCoxTransformer:\n",
        "    def __init__(self, lambda_val=0.1):\n",
        "        self.lambda_val = lambda_val\n",
        "        self.consumption_species = ['NH3', 'O2']\n",
        "\n",
        "    def transform(self, Y, species):\n",
        "        \"\"\"Apply customized Box-Cox transformation\"\"\"\n",
        "        Y_transformed = np.zeros_like(Y)\n",
        "        for i, sp in enumerate(species):\n",
        "            if sp in self.consumption_species:\n",
        "                # Consumption species transformation\n",
        "                Y_transformed[:, i] = (Y[:, i]**self.lambda_val - 1) / self.lambda_val\n",
        "            else:\n",
        "                # Production species transformation\n",
        "                Y_transformed[:, i] = ((1 - Y[:, i])**self.lambda_val - 1) / self.lambda_val\n",
        "        return Y_transformed\n",
        "\n",
        "    def inverse_transform(self, Y_transformed, species):\n",
        "        \"\"\"Inverse of the Box-Cox transformation\"\"\"\n",
        "        Y = np.zeros_like(Y_transformed)\n",
        "        for i, sp in enumerate(species):\n",
        "            if sp in self.consumption_species:\n",
        "                # Inverse for consumption species\n",
        "                Y[:, i] = (self.lambda_val * Y_transformed[:, i] + 1)**(1/self.lambda_val)\n",
        "            else:\n",
        "                # Inverse for production species\n",
        "                Y[:, i] = 1 - (self.lambda_val * Y_transformed[:, i] + 1)**(1/self.lambda_val)\n",
        "        return Y\n",
        "\n",
        "# =============================================\n",
        "# 5. Neural ODE Model Definition\n",
        "# =============================================\n",
        "\n",
        "class GroupedODEFunc(nn.Module):\n",
        "    def __init__(self, input_dim, group_name, target_species):\n",
        "        super().__init__()\n",
        "        assert input_dim == 7, f\"Model requires 7 input features, got {input_dim}\"\n",
        "        self.group_name = group_name\n",
        "        self.target_species = target_species\n",
        "\n",
        "        # Unified architecture with 4 hidden layers\n",
        "        hidden_dim = 192 if target_species in ['NH3', 'O2', 'H2O'] else 384\n",
        "        self.net = nn.Sequential(\n",
        "            # Input layer (not counted as hidden)\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Hidden Layer 1\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.SiLU(),\n",
        "\n",
        "            # Hidden Layer 2\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.SiLU(),\n",
        "\n",
        "            # Hidden Layer 3\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.SiLU(),\n",
        "\n",
        "            # Hidden Layer 4\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.SiLU(),\n",
        "\n",
        "            # Hidden Layer 5\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.SiLU(),\n",
        "\n",
        "            # Output layer (not counted as hidden)\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        )\n",
        "\n",
        "        # Enhanced residual connection\n",
        "        self.skip = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        ) if input_dim != 1 else None\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        return self.net(x) + (self.skip(x) if self.skip else 0)\n",
        "\n",
        "# =============================================\n",
        "# 6. Training Procedure\n",
        "# =============================================\n",
        "\n",
        "def train_node_model(data, target_species, species_list, group_name, n_epochs=5000, batch_size=256):\n",
        "    # Set up transformer\n",
        "    transformer = BoxCoxTransformer(lambda_val=0.1)\n",
        "\n",
        "    # Prepare data\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "    weights_list = []\n",
        "\n",
        "    # Define ACTUAL species used in model (exclude N2)\n",
        "    model_species = [sp for sp in species_list if sp != 'N2']\n",
        "    assert len(model_species) == 6, \"Should have exactly 6 species (excl. N2)\"\n",
        "\n",
        "    for condition in data:\n",
        "        # Transform mass fractions\n",
        "        Y_transformed = transformer.transform(condition['Y'][:, [species_list.index(sp) for sp in model_species]], model_species)\n",
        "\n",
        "        # Normalize temperature using calculated max_temp\n",
        "        T_norm = condition['T'] / max_temp\n",
        "\n",
        "        # Create input features (Y and T)\n",
        "        X = np.concatenate([Y_transformed, T_norm.reshape(-1, 1)], axis=1)\n",
        "\n",
        "        # Get target (dY/dt for target species)\n",
        "        target_idx = species_list.index(target_species)\n",
        "        y = condition['dYdt'][:, target_idx]\n",
        "\n",
        "        # Get weights\n",
        "        weights = condition['weights']\n",
        "\n",
        "        X_list.append(X)\n",
        "        y_list.append(y)\n",
        "        weights_list.append(weights)\n",
        "\n",
        "    # Concatenate all data\n",
        "    X_all = np.concatenate(X_list)\n",
        "    y_all = np.concatenate(y_list)\n",
        "\n",
        "    # # =============================================\n",
        "    # # NEW: Data Export Section\n",
        "    # # =============================================\n",
        "    # def save_debug_data(X, y, species_list, target_species, group_name):\n",
        "    #     import pandas as pd\n",
        "    #     import os\n",
        "\n",
        "    #     # Create debug directory if needed\n",
        "    #     os.makedirs('debug_data', exist_ok=True)\n",
        "\n",
        "    #     # Prepare column names\n",
        "    #     input_species = [sp for sp in species_list if sp != 'N2']\n",
        "    #     feature_columns = input_species + ['T_normalized']\n",
        "\n",
        "    #     # Create DataFrames\n",
        "    #     df_X = pd.DataFrame(X, columns=feature_columns)\n",
        "    #     df_y = pd.DataFrame(y, columns=[f'd{target_species}_dt'])\n",
        "\n",
        "    #     # Save to CSV\n",
        "    #     timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
        "    #     filename = f\"debug_data/{target_species}_{group_name}_{timestamp}\"\n",
        "\n",
        "    #     df_X.to_csv(f\"{filename}_X.csv\", index=False)\n",
        "    #     df_y.to_csv(f\"{filename}_y.csv\", index=False)\n",
        "\n",
        "    #     # Save human-readable text version\n",
        "    #     with open(f\"{filename}_summary.txt\", 'w') as f:\n",
        "    #         f.write(f\"=== Debug Data for {target_species} ({group_name} group) ===\\n\")\n",
        "    #         f.write(f\"Generated at: {timestamp}\\n\\n\")\n",
        "\n",
        "    #         f.write(\"=== Input Features (X_all) ===\\n\")\n",
        "    #         f.write(f\"Shape: {X.shape}\\n\")\n",
        "    #         f.write(\"First 5 rows:\\n\")\n",
        "    #         f.write(df_X.head().to_string() + \"\\n\\n\")\n",
        "\n",
        "    #         f.write(\"=== Targets (y_all) ===\\n\")\n",
        "    #         f.write(f\"Shape: {y.shape}\\n\")\n",
        "    #         f.write(\"Statistics:\\n\")\n",
        "    #         f.write(df_y.describe().to_string() + \"\\n\")\n",
        "\n",
        "    #         f.write(\"\\n=== Feature Statistics ===\\n\")\n",
        "    #         f.write(df_X.describe().to_string())\n",
        "\n",
        "    #     print(f\"Debug data saved to {filename}_[X.csv|y.csv|summary.txt]\")\n",
        "\n",
        "    # # Call the debug function\n",
        "    # save_debug_data(X_all, y_all, species_list, target_species, group_name)\n",
        "\n",
        "    # Standardize dY/dt labels\n",
        "    dYdt_mean, dYdt_std = np.mean(y_all), np.std(y_all)\n",
        "    y_all = (y_all - dYdt_mean) / (dYdt_std + 1e-12)  # Prevent division by zero\n",
        "\n",
        "    weights_all = np.concatenate(weights_list)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_tensor = torch.FloatTensor(X_all).to(device)\n",
        "    y_tensor = torch.FloatTensor(y_all).to(device)\n",
        "    weights_tensor = torch.FloatTensor(weights_all).to(device)\n",
        "\n",
        "    # Create model\n",
        "    input_dim = X_all.shape[1]\n",
        "    assert input_dim == 7, f\"Expected 7 input features, got {input_dim}\"\n",
        "\n",
        "    model = GroupedODEFunc(\n",
        "        input_dim=input_dim,\n",
        "        group_name=group_name,\n",
        "        target_species=target_species).to(device)\n",
        "\n",
        "    # Store for inverse transform during inference\n",
        "    model.dYdt_mean = dYdt_mean\n",
        "    model.dYdt_std = dYdt_std\n",
        "\n",
        "    # Optimizer Initialization\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=5e-3)\n",
        "\n",
        "    # Learning Rate Scheduling\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='min',\n",
        "        factor=0.5,\n",
        "        patience=100,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Weighted Loss Function\n",
        "    def weighted_mse(pred, target):\n",
        "        # More aggressive weighting for ignition phases\n",
        "        weights = torch.log1p(torch.abs(target)) + 1.0\n",
        "        return torch.mean(weights * (pred - target)**2)\n",
        "\n",
        "    loss_fn = weighted_mse\n",
        "\n",
        "    # Training loop\n",
        "    losses = []\n",
        "    for epoch in tqdm(range(n_epochs), desc=f\"Training {target_species} NODE\"):\n",
        "        # Sample batch with weights\n",
        "        batch_indices = np.random.choice(len(X_all), size=batch_size, p=weights_all/weights_all.sum())\n",
        "        X_batch = X_tensor[batch_indices]\n",
        "        y_batch = y_tensor[batch_indices]\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(None, X_batch).squeeze()\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Inside training loop (after loss.backward()):\n",
        "        scheduler.step(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    # Plot training loss\n",
        "    plt.figure()\n",
        "    plt.plot(losses)\n",
        "    plt.yscale('log')\n",
        "    plt.title(f\"Training Loss for {target_species}\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MSE Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_temperature_group_models(all_data, species_list):\n",
        "    # First filter out N2 from species list\n",
        "    model_species = [sp for sp in species_list if sp != 'N2']\n",
        "    print(f\"Using species: {model_species} (N2 excluded)\")\n",
        "\n",
        "    # Group data by temperature ranges - MODIFIED to include boundary temps in both groups\n",
        "    grouped_data = {'high': [], 'medium': [], 'low': []}\n",
        "\n",
        "    for condition in all_data:\n",
        "        T_init = condition['T_init']\n",
        "        if T_init >= 1900:  # High group\n",
        "            grouped_data['high'].append(condition)\n",
        "        if 1500 <= T_init <= 1900:  # Medium group (includes 1900)\n",
        "            grouped_data['medium'].append(condition)\n",
        "        if T_init <= 1500:  # Low group (includes 1500)\n",
        "            grouped_data['low'].append(condition)\n",
        "\n",
        "    # Rest of the function remains the same...\n",
        "    node_models = {}\n",
        "\n",
        "    for group_name in ['high', 'medium', 'low']:\n",
        "        print(f\"\\nTraining {group_name.upper()} temperature group models:\\n\")\n",
        "        group_data = grouped_data[group_name]\n",
        "\n",
        "        weighted_group_data = calculate_sampling_weights(group_data, target_species='NH3')\n",
        "\n",
        "        for target_species in model_species:\n",
        "            print(f\"\\nTraining {target_species} ({group_name.upper()} group)\")\n",
        "            model = train_node_model(weighted_group_data, target_species, species_list, group_name = group_name)\n",
        "            node_models[f\"{target_species}_{group_name}\"] = model\n",
        "\n",
        "    return node_models\n"
      ],
      "metadata": {
        "id": "BBdGZGc7-yb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train with temperature grouping\n",
        "print(\"Training temperature-grouped NODE models...\\n\")\n",
        "\n",
        "# Calculate maximum temperature across all data points\n",
        "global max_temp\n",
        "max_temp = max(\n",
        "    np.max(condition['T'])      # Get max T for this condition\n",
        "    for condition in all_data   # Loop through all conditions\n",
        ")\n",
        "print(f\"Maximum temperature across all data points: {max_temp}\")\n",
        "\n",
        "node_models = train_temperature_group_models(all_data, species)\n"
      ],
      "metadata": {
        "id": "Vo3YQL-ICNjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/DATA.zip /content/debug_data/"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PNb8IW40h1EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Save all 18 models\n",
        "torch.save(node_models, 'grouped_ammonia_models.pth')\n",
        "print(\"Saved 18 models (6 species × 3 temp groups) to grouped_ammonia_models.pth\")\n"
      ],
      "metadata": {
        "id": "ZYR5UExvCpV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Validation of NODE Model\n",
        "\n",
        "# =============================================\n",
        "# Constants\n",
        "# =============================================\n",
        "R_UNIV = 8.314  # Universal gas constant [J/(mol·K)]\n",
        "\n",
        "# =============================================\n",
        "# Thermodynamic Data (NASA polynomials for species)\n",
        "# =============================================\n",
        "# NASA 7-coefficient polynomial format: [a_low_1, a_low_2, ..., a_low_7, T_low, T_high, a_high_1, ..., a_high_7] (Burcat Database)\n",
        "# NASA_COEFFS = {\n",
        "#     'SPECIES_NAME': {\n",
        "#         'coeffs': [\n",
        "#             # Low-T range coefficients (200-1000K) [a1, a2, a3, a4, a5, a6, a7]\n",
        "#             # High-T range coefficients (1000-6000K) [b1, b2, b3, b4, b5, b6, b7]\n",
        "#         ],\n",
        "#         'T_low': 200.0,    # Minimum temperature for low-T coefficients (K)\n",
        "#         'T_high': 1000.0,  # Transition temperature between low/high ranges (K)\n",
        "#         'Mw': 17.031       # Molecular weight (g/mol)\n",
        "#     }\n",
        "# }\n",
        "\n",
        "NASA_COEFFS = {\n",
        "    'H2': {\n",
        "        'coeffs': [\n",
        "            2.344331, 0.007980, -1.947815e-05, 2.015721e-08, -7.376118e-12, -917.935, 0.683010,\n",
        "            3.337279, 0.002470, -8.180640e-07, 1.277629e-10, -6.378056e-15, -950.158, -3.205023\n",
        "        ],\n",
        "        'T_low': 200.0, 'T_high': 1000.0, 'Mw': 2.016  # Molecular weight [g/mol]\n",
        "    },\n",
        "    'O2': {\n",
        "        'coeffs': [\n",
        "            3.782456, -0.002996, 9.847302e-06, -9.681295e-09, 3.243728e-12, -1063.943, 3.657676,\n",
        "            3.660961, 0.001656, -4.599965e-07, 6.669201e-11, -3.067911e-15, -1215.977, 3.415362\n",
        "        ],\n",
        "        'T_low': 200.0, 'T_high': 1000.0, 'Mw': 32.00\n",
        "    },\n",
        "    'H2O': {\n",
        "        'coeffs': [\n",
        "            4.198640, -0.002036, 4.301402e-06, -2.368140e-09, 5.087687e-13, -30293.726, -0.849009,\n",
        "            3.033992, 0.002176, -1.640725e-07, -9.704198e-11, 1.682009e-14, -30004.488, 4.966770\n",
        "        ],\n",
        "        'T_low': 200.0, 'T_high': 1000.0, 'Mw': 18.015\n",
        "    },\n",
        "    'NH3': {\n",
        "        'coeffs': [\n",
        "            3.578323, -0.000610, 2.500000e-06, -2.000000e-09, 5.000000e-13, -10623.7, 2.203030,\n",
        "            3.568874, 0.001366, -1.983749e-06, 1.426804e-09, -3.836744e-13, -1020.896, 5.872526\n",
        "        ],\n",
        "        'T_low': 200.0, 'T_high': 1000.0, 'Mw': 17.031\n",
        "    },\n",
        "    'OH': {\n",
        "        'coeffs': [\n",
        "            3.637268, 0.000506, -8.814150e-07, 9.804318e-10, -4.384130e-13, 3419.309, 2.932866,\n",
        "            3.697578, 0.001012, -1.321330e-06, 1.410378e-09, -4.889708e-13, 3369.887, -1.272096\n",
        "        ],\n",
        "        'T_low': 200.0, 'T_high': 1000.0, 'Mw': 17.007\n",
        "    },\n",
        "    'NO': {\n",
        "        'coeffs': [\n",
        "            4.046189, -0.002470, 6.348420e-06, -5.961540e-09, 2.156450e-12, 983.261, 5.980056,\n",
        "            3.531005, -0.000123, -1.182722e-06, 2.655356e-09, -1.322536e-12, 976.287, 6.500787\n",
        "        ],\n",
        "        'T_low': 200.0, 'T_high': 1000.0, 'Mw': 30.006\n",
        "    },\n",
        "    'N2': {\n",
        "        'coeffs': [\n",
        "            3.298677, 0.001408, -3.963222e-06, 5.641515e-09, -2.444854e-12, -1020.900, 3.950372,\n",
        "            2.926640, 0.001487, -2.842380e-06, 3.365680e-09, -1.688258e-12, -905.851, 5.980528\n",
        "        ],\n",
        "        'T_low': 200.0, 'T_high': 1000.0, 'Mw': 28.013\n",
        "    }\n",
        "}\n",
        "\n",
        "def compute_h_i(T, species):\n",
        "    \"\"\"Compute specific enthalpy h_i(T) [J/kg] for a species using NASA polynomials.\"\"\"\n",
        "    coeffs = NASA_COEFFS[species]['coeffs']\n",
        "    T_mid = NASA_COEFFS[species]['T_low']\n",
        "    if T <= T_mid:\n",
        "        a = coeffs[:7]\n",
        "    else:\n",
        "        a = coeffs[7:14]\n",
        "\n",
        "    # Enthalpy polynomial: h_i(T)/RT = a1 + a2*T/2 + a3*T^2/3 + a4*T^3/4 + a5*T^4/5 + a6/T\n",
        "    h_RT = (\n",
        "        a[0] +\n",
        "        a[1] * T / 2 +\n",
        "        a[2] * T**2 / 3 +\n",
        "        a[3] * T**3 / 4 +\n",
        "        a[4] * T**4 / 5 +\n",
        "        a[5] / T\n",
        "    )\n",
        "    h_i = h_RT * R_UNIV * T  # [J/mol]\n",
        "    h_i /= NASA_COEFFS[species]['Mw'] / 1000.0  # Convert to [J/kg]\n",
        "    return h_i\n",
        "\n",
        "def compute_cp_i(T, species):\n",
        "    \"\"\"Compute specific heat cp_i(T) [J/(kg·K)] for a species.\"\"\"\n",
        "    coeffs = NASA_COEFFS[species]['coeffs']\n",
        "    T_mid = NASA_COEFFS[species]['T_low']\n",
        "    if T <= T_mid:\n",
        "        a = coeffs[:7]\n",
        "    else:\n",
        "        a = coeffs[7:14]\n",
        "\n",
        "    # cp_i/R = a1 + a2*T + a3*T^2 + a4*T^3 + a5*T^4\n",
        "    cp_R = (\n",
        "        a[0] +\n",
        "        a[1] * T +\n",
        "        a[2] * T**2 +\n",
        "        a[3] * T**3 +\n",
        "        a[4] * T**4\n",
        "    )\n",
        "    cp_i = cp_R * R_UNIV  # [J/(mol·K)]\n",
        "    cp_i /= NASA_COEFFS[species]['Mw'] / 1000.0  # Convert to [J/(kg·K)]\n",
        "    return cp_i\n",
        "\n",
        "def update_temperature(Y, T, dYdt, species_list):\n",
        "    \"\"\"\n",
        "    Update temperature in a constant-pressure, adiabatic reactor.\n",
        "\n",
        "    Args:\n",
        "        Y (dict): Mass fractions {species: Y_i}.\n",
        "        T (float): Current temperature [K].\n",
        "        dYdt (dict): Rates of change of mass fractions {species: dY_i/dt}.\n",
        "        dt (float): Time step [s].\n",
        "        species_list (list): List of species names.\n",
        "\n",
        "    Returns:\n",
        "        T_new (float): Updated temperature [K].\n",
        "    \"\"\"\n",
        "    # Compute sum(dY_i/dt * h_i(T))\n",
        "    sum_dYdt_h = 0.0\n",
        "    for species in species_list:\n",
        "        h_i = compute_h_i(T, species)\n",
        "        sum_dYdt_h += dYdt[species] * h_i\n",
        "\n",
        "    # Compute mixture cp = sum(Y_i * cp_i(T))\n",
        "    cp_mix = 0.0\n",
        "    for species in species_list:\n",
        "        cp_i = compute_cp_i(T, species)\n",
        "        cp_mix += Y[species] * cp_i\n",
        "\n",
        "    # Compute dT/dt = -sum(dY_i/dt * h_i(T)) / cp_mix\n",
        "    dTdt = -sum_dYdt_h / cp_mix\n",
        "\n",
        "    return dTdt\n",
        "\n",
        "\n",
        "def validate_node_vs_cantera(node_models, T_init=1900, phi=1.2, t_end=5):\n",
        "    \"\"\"\n",
        "    Compare NODE and Cantera simulations for a single initial condition.\n",
        "\n",
        "    Args:\n",
        "        node_models: Dictionary of trained models (e.g., {'NH3_high': model, ...})\n",
        "        T_init: Initial temperature (K)\n",
        "        phi: Equivalence ratio\n",
        "        t_end: Simulation end time (s)\n",
        "    \"\"\"\n",
        "    # --------------------------------------------------------------------------\n",
        "    # 1. Set up Cantera simulation (Ground Truth)\n",
        "    # --------------------------------------------------------------------------\n",
        "    gas = ct.Solution('/content/sample_data/okafor.yaml')\n",
        "    gas.set_equivalence_ratio(phi, 'NH3', 'O2:1.0, N2:3.76')\n",
        "    gas.TP = T_init, ct.one_atm\n",
        "\n",
        "    # Create reactor\n",
        "    reactor = ct.IdealGasReactor(gas)\n",
        "    sim = ct.ReactorNet([reactor])\n",
        "    sim.atol, sim.rtol = 1e-14, 1e-16\n",
        "\n",
        "    # Time points (log-spaced for ignition resolution)\n",
        "    t_eval = np.linspace(0, t_end, 500)\n",
        "\n",
        "    # Storage\n",
        "    cantera_results = {\n",
        "        'time': [],\n",
        "        'T': [],\n",
        "        'Y': {sp: [] for sp in ['NH3', 'O2', 'H2O', 'N2']}  # Key species to plot\n",
        "    }\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # 2. Set up NODE simulation\n",
        "    # --------------------------------------------------------------------------\n",
        "    # gas_node = ct.Solution('/content/sample_data/okafor.yaml')  # Separate instance for NODE\n",
        "\n",
        "    # Initial mass fractions (match Cantera's initialization)\n",
        "    Y0 = {sp: gas[sp].Y[0] for sp in ['NH3', 'O2', 'H2', 'OH', 'H2O', 'NO']}\n",
        "    Y0['N2'] = 1 - sum(Y0.values())  # Enforce mass conservation\n",
        "\n",
        "    # Normalize initial state for NODE\n",
        "    transformer = BoxCoxTransformer(lambda_val=0.1)\n",
        "    species_order = ['NH3', 'O2', 'H2', 'OH', 'H2O', 'NO']\n",
        "    Y0_transformed = transformer.transform(np.array([Y0[sp] for sp in species_order]).reshape(1, -1), species_order).flatten()\n",
        "    T0_norm = T_init / max_temp  # Use max_temp from training\n",
        "\n",
        "    # Initial state tensor\n",
        "    x0 = torch.tensor(np.concatenate([Y0_transformed, [T0_norm]]), dtype=torch.float32).to(device)\n",
        "\n",
        "    # Debug: Print shapes to verify\n",
        "    print(f\"Input shape to NODE: {x0.shape}\")  # Should be (7,)\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # 3. Define NODE ODE system\n",
        "    # --------------------------------------------------------------------------\n",
        "    def node_system(t, x):\n",
        "        \"\"\"ODE system for NODE integration (fixed dimensionality)\"\"\"\n",
        "        # Ensure input is 2D [batch=1, features=7]\n",
        "        x_in = x.unsqueeze(0) if x.dim() == 1 else x  # Shape: [1, 7]\n",
        "\n",
        "        # Denormalize input\n",
        "        Y_transformed = x_in[0, :-1].cpu().numpy()  # First (only) batch, exclude T\n",
        "        T_norm = x_in[0, -1].item()\n",
        "\n",
        "        Y = transformer.inverse_transform(Y_transformed.reshape(1, -1), species_order).flatten()\n",
        "        T = T_norm * max_temp\n",
        "\n",
        "        print(f\"Called at t={t:.3e}s, T={T:.1f}K\")\n",
        "\n",
        "        # Hybrid mode: Use Cantera below threshold\n",
        "        if T < 1400:\n",
        "            gas.TPY = T, ct.one_atm, dict(zip(species_order, Y))\n",
        "            wdot = gas.net_production_rates * gas.molecular_weights / gas.density\n",
        "            dYdt_phys = {sp: wdot[gas.species_index(sp)] for sp in species_order}\n",
        "        else:\n",
        "            # Select model group dynamically\n",
        "            group = 'high' if T >= 1900 else 'medium' if T >= 1500 else 'low'\n",
        "\n",
        "            # Predict dY/dt for each species\n",
        "            dYdt_phys = {}\n",
        "            for i, sp in enumerate(species_order):\n",
        "                model = node_models[f\"{sp}_{group}\"]\n",
        "                pred = model(None, x_in)\n",
        "                dYdt_phys[sp] = pred.item() * model.dYdt_std + model.dYdt_mean\n",
        "\n",
        "        # Update temperature (using thermodynamics)\n",
        "        dTdt = update_temperature(Y = dict(zip(species_order, Y)), T = T, dYdt = dYdt_phys, species_list = species_order)\n",
        "\n",
        "        # Return derivatives (now with dT/dt)\n",
        "        dYdt_transformed = (np.array([dYdt_phys[sp] for sp in species_order]) - model.dYdt_mean) / model.dYdt_std\n",
        "\n",
        "        dTdt_transformed = dTdt / max_temp    # Normalized derivative\n",
        "\n",
        "        # Output must match input shape [7]\n",
        "        return torch.tensor(np.concatenate([dYdt_transformed, [dTdt_transformed]]), dtype=torch.float32).to(device)\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # 4. Run simulations\n",
        "    # --------------------------------------------------------------------------\n",
        "    # Integrate NODE\n",
        "    t_eval_tensor = torch.tensor(t_eval, dtype=torch.float32).to(device)\n",
        "    node_sol = odeint(node_system, x0, t_eval_tensor, method=\"scipy_solver\", rtol=1e-6, atol=1e-8, options={\"method\": \"BDF\", \"min_step\": 1e-10})\n",
        "    # print(f\"Solver stats: {node_sol.stats}\")\n",
        "    print(node_sol)\n",
        "    print(f\"node_sol shape: {node_sol.shape}\")\n",
        "\n",
        "    # Run Cantera\n",
        "    for t in t_eval:\n",
        "        sim.advance(t)\n",
        "        cantera_results['time'].append(t)\n",
        "        cantera_results['T'].append(reactor.T)\n",
        "        for sp in ['NH3', 'O2', 'H2O', 'N2']:\n",
        "            cantera_results['Y'][sp].append(gas[sp].Y[0])\n",
        "\n",
        "    # Process NODE results with N2 reconstruction\n",
        "    node_results = {'time': t_eval, 'T': [], 'Y': {sp: [] for sp in ['NH3', 'O2', 'H2O', 'N2']}}\n",
        "    for i, t in enumerate(t_eval):\n",
        "        Y_transformed = node_sol[i, :-1].cpu().numpy()\n",
        "        Y = transformer.inverse_transform(Y_transformed.reshape(1, -1), species_order).flatten()\n",
        "        node_results['T'].append(node_sol[i, -1].item() * max_temp)\n",
        "        node_results['Y']['NH3'].append(Y[0])\n",
        "        node_results['Y']['O2'].append(Y[1])\n",
        "        node_results['Y']['H2O'].append(Y[4])       # H2O is 5th in species order\n",
        "        node_results['Y']['N2'].append(1 - sum(Y))  # Mass conservation\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # 5. Plot comparison\n",
        "    # --------------------------------------------------------------------------\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Temperature plot\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(cantera_results['time'], cantera_results['T'], 'r--', label='Cantera')\n",
        "    plt.plot(node_results['time'], node_results['T'], 'b-', label='NODE')\n",
        "    plt.ylabel('Temperature (K)')\n",
        "    plt.xscale('log')\n",
        "    plt.legend()\n",
        "    plt.title(f'NH3 Combustion (T={T_init}K, ϕ={phi})')\n",
        "\n",
        "    # Mass fractions plot\n",
        "    plt.subplot(2, 1, 2)\n",
        "    for sp in ['NH3', 'O2', 'H2O', 'N2']:\n",
        "        plt.plot(cantera_results['time'], cantera_results['Y'][sp], '--',\n",
        "                label=f'Cantera {sp}')\n",
        "        plt.plot(node_results['time'], node_results['Y'][sp], '-',\n",
        "                label=f'NODE {sp}')\n",
        "    plt.ylabel('Mass Fraction')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.xscale('log')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "node_models = torch.load('grouped_ammonia_models.pth', weights_only=False)  # Loads the trained models\n",
        "validate_node_vs_cantera(node_models, T_init=1300, phi=1.0)\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "vwgrN4-naEQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_nasa_coefficients(mechanism_path, species_list):\n",
        "    \"\"\"\n",
        "    Extract NASA coefficients for specified species from a Cantera mechanism file.\n",
        "\n",
        "    Args:\n",
        "        mechanism_path: Path to .yaml/.cti mechanism file\n",
        "        species_list: List of species names (e.g., ['NH3','NO','OH','N2'])\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of NASA coefficients in your preferred format\n",
        "    \"\"\"\n",
        "    gas = ct.Solution(mechanism_path)\n",
        "    nasa_data = {}\n",
        "\n",
        "    for species in species_list:\n",
        "        try:\n",
        "            thermo = gas.species(species).thermo\n",
        "            if not isinstance(thermo, ct.NasaPoly2):\n",
        "                print(f\"Warning: {species} uses {type(thermo).__name__} thermo model (not NASA)\")\n",
        "                continue\n",
        "\n",
        "            nasa_data[species] = {\n",
        "                'coeffs': list(thermo.low_coeffs) + list(thermo.high_coeffs),\n",
        "                'T_low': thermo.min_temp,\n",
        "                'T_high': thermo.max_temp,\n",
        "                'Mw': gas.molecular_weights[gas.species_index(species)]\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {species}: {str(e)}\")\n",
        "\n",
        "    return nasa_data\n",
        "\n",
        "# Usage example:\n",
        "mechanism_path = '/content/sample_data/okafor.yaml'  # Your mechanism file\n",
        "species_of_interest = ['NH3', 'OH', 'NO', 'N2', 'H2', 'O2', 'H2O', 'N', 'NH', 'NH2', 'N2O', 'NO2']\n",
        "\n",
        "NASA_COEFFS = extract_nasa_coefficients(mechanism_path, species_of_interest)    # Instead of manually writing the values"
      ],
      "metadata": {
        "id": "JWqYb8BlXpui"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}